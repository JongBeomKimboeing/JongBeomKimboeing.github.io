---
layout: post
title: RNN 기초
description: "Image classification with custom image(my data)"
modified: 2020-05-17
tags: [김성훈,DL]
categories: [김성훈DL]
---
# RNN 기초
RNN을 이용하여 hihello 문장을 학습시켜본다.
```python
import tensorflow as tf
import numpy as np

idx2char = ['h','i','e','l','o']
# Teach hello: hihell -> ihello
# x_data = [[0, 1, 0, 2, 3, 3]]  # hihell

y_data = [[1, 0, 2, 3, 3, 4]]

num_classes = 5
input_dim = 5
sequence_length = 6
learning_rate = 0.1

x_one_hot = np.array([[[1, 0, 0, 0, 0],    # h 0
                       [0, 1, 0, 0, 0],    # i 1
                       [1, 0, 0, 0, 0],    # h 0
                       [0, 0, 1, 0, 0],    # e 2
                       [0, 0, 0, 1, 0],    # l 3
                       [0, 0, 0, 1, 0]]],  # l 3
                     dtype=np.float32)

y_one_hot = tf.keras.utils.to_categorical(y_data, num_classes= num_classes)
print(x_one_hot.shape) # result: (1, 6, 5) == (batch, length of sequence(=length of RNN), size of input)
print(y_one_hot.shape) # result: (1, 6, 5) == (배치사이즈,RNN 길이 , 입력 수)

tf.model = tf.keras.Sequential()
cell = tf.keras.layers.LSTMCell(units= num_classes, input_shape=(sequence_length, input_dim))
tf.model.add(tf.keras.layers.RNN(cell=cell, return_sequences=True))

tf.model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=num_classes, activation='softmax')))
# 하나의 RNN cell마다 fully connected layer와 softmax activation function이 적용됨.
tf.model.compile(loss= 'categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), metrics=['accuracy'])

tf.model.fit(x_one_hot, y_one_hot, epochs=50)
tf.model.summary()

predictions = tf.model.predict(x_one_hot)
for i, prediction in enumerate(predictions):
    print(prediction)
    result_str = [idx2char[c] for c in np.argmax(prediction, axis=1)]
    print("\tPrediction str: ", ''.join(result_str))
```
